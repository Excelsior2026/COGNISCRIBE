# CLINISCRIBE Environment Configuration
# Copy this file to .env and configure for your environment

# ==================== SECURITY ====================

# Authentication (REQUIRED for production)
# Generate secure API keys: python -c "import secrets; print(secrets.token_urlsafe(32))"
CLINISCRIBE_AUTH_ENABLED=true
CLINISCRIBE_API_KEYS=your-secure-api-key-1,your-secure-api-key-2

# Development key (only used if API_KEYS not set)
# CLINISCRIBE_DEV_KEY=dev-key-for-testing

# Rate Limiting
CLINISCRIBE_RATE_LIMIT_ENABLED=true
CLINISCRIBE_RATE_LIMIT_REQUESTS=10
CLINISCRIBE_RATE_LIMIT_WINDOW=60

# ==================== API SETTINGS ====================

# Server configuration
HOST=0.0.0.0
PORT=8080
LOG_LEVEL=INFO

# CORS origins (comma-separated)
CORS_ALLOW_ORIGINS=http://localhost:5173,http://127.0.0.1:5173
CORS_ALLOW_CREDENTIALS=false

# ==================== STORAGE ====================

# Data directory (optional, uses platform defaults if not set)
# COGNISCRIBE_DATA_DIR=/path/to/data

# Audio storage
# AUDIO_STORAGE_DIR=/custom/audio/path
# TEMP_AUDIO_DIR=/custom/temp/path
AUDIO_RETENTION_DAYS=7

# File upload limits
MAX_FILE_SIZE_MB=1000
MAX_CHUNK_MB=8

# ==================== AUDIO PROCESSING ====================

# DeepFilterNet (optional offline audio enhancement)
DEEPFILTERNET_ENABLED=false
DEEPFILTERNET_BIN=deep-filter
# DEEPFILTERNET_MODEL=/path/to/custom/model
DEEPFILTERNET_USE_POSTFILTER=true

# ==================== AI MODELS ====================

# Whisper transcription model
# Options: tiny, base, small, medium, large-v3
WHISPER_MODEL=base

# GPU acceleration (requires CUDA)
USE_GPU=false

# Ollama LLM for summarization
OLLAMA_HOST=localhost
OLLAMA_PORT=11434
OLLAMA_MODEL=llama3.1:8b
OLLAMA_TIMEOUT=300

# ==================== DEVELOPMENT ====================

# Disable security for local development (NOT for production!)
# CLINISCRIBE_AUTH_ENABLED=false
# CLINISCRIBE_RATE_LIMIT_ENABLED=false
